{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "469a7167",
   "metadata": {},
   "source": [
    "Here are some of the most common uses for tesuract. This is not comprehensive, but merely highlights the strengths and flexibility of tesuract. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d7c3d9",
   "metadata": {},
   "source": [
    "## Polynomial regression\n",
    "\n",
    "Here we show how tesuract can be used to construct (and easily fit) a Legendre polynomial) to data for more than just a single-dimension. This highlights the ease to which we can create complex interacting polynomial functions that scale well for higher dimensions, which cannot be done without some care in say scikit-learn using the polynomial feature library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c2cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the libraries we will use\n",
    "import numpy as np\n",
    "import tesuract\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff5a983",
   "metadata": {},
   "source": [
    "We will create a five-dimensional regression problem with 100 samples. Thus, this will not be as trivial as a one-dimensional polynomial fitting. In this case, no finite polynomial will return an exact solution so this will be a little bit of a challenge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414ad643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a data set for our regression problem\n",
    "from sklearn.datasets import make_friedman1\n",
    "X,y = make_friedman1(n_samples=100,n_features=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2ab37a",
   "metadata": {},
   "source": [
    "For the polynomial regression, it is not required, but recommended, to normalize the input X data to $[-1,1]$. Since the ``make_friedman1`` function is on the unit interval, this is very easy. Once we do this, we can now fit using a polynomial. See the later tutorials on how to do this without having to rescale the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882aaeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the input\n",
    "X = 2*X - 1\n",
    "# center and scale the output as well for good measure (not required)\n",
    "y = (y - y.mean())/np.sqrt(np.var(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7215e1b",
   "metadata": {},
   "source": [
    "Since the regression test problem is in fact a sinusoidal function, let us try a higher order polynomial. Now, in order to create a five-dimensional polynomial using the tools already available in sklearn, we would have to create a one-dimensional monomial feature and then, in the simplest way, we can take a full tensor product of all interaction for each dimension. This means that if we have an 8th order polynomial in each of the five dimensions (each with 9 coefficient including the bias term), we would have $9^5 = 59,049$ coefficients to learn! This would lead to terms that have a total order (sum of exponents) of $8\\times5 = 40$, which is not ideal. We can limit the number of interaction terms by using Smolyak type expansions from uncertainty quantification, a.k.a., polynomial chaos expansions. In this case, if we want a total order of 8, then the total number of terms is only $1,287$. This is all done under the hood, and in a later tutorial we will explain what's going on. But for now, just trust me!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "501cdc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCEReg(coef=array([-0.05005908,  0.50313008,  0.42071285, ..., -0.00545481,\n",
       "        0.07065965, -0.01712974]),\n",
       "       order=8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an 8th order polynomial (total order amongst all dimensions)\n",
    "pce = tesuract.PCEReg(order=8)\n",
    "pce.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12a1e16",
   "metadata": {},
   "source": [
    "And that's it. We just used the default linear least squares estimator to fit the data with an 8th order five-dimensional polynomial. Just to show you this is actually quite complex, we can show what's called the multi-index set, which represents all the interaction terms between the orthogonal one-dimensional Legendre polynomial.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d38bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, 0, 7],\n",
       "       [0, 0, 0, 1, 7],\n",
       "       [0, 0, 0, 0, 8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pce.mindex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e45421",
   "metadata": {},
   "source": [
    "So for example, the second-to-last multi-index corresponds to a five-dimensional polynomial basis function (like a Fourier basis but with polynomials) as the product of the first order 1-D Legendre polynomial of the fourth dimension and the 8th order 1-D Legendre polynomial of the fifth dimenion.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c443c5b",
   "metadata": {},
   "source": [
    "Now that we know how to create a multi-variate polynomial expansion or Polynomial Chaos Expansion (PCE), how to do we evaluate it's accuracy. Here is where tesuract really shine!\n",
    "\n",
    "The PCEReg class is actually an sklearn estimator class. This means it can be fully integrated in the sklearn universe. In particular, we can wrap the PCEReg class into say the cross_val_score function in sklearn. This computes the k-fold cross validation score of any sklearn estimator. Let's try this to get a score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabec643",
   "metadata": {},
   "source": [
    "## Scoring the regressor and comparing to different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80334a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCE score is 0.836\n"
     ]
    }
   ],
   "source": [
    "# compute the cross validation score (5-fold by default)\n",
    "# of the pce we constructed earlier, i.e. 8th order linear fit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "pce = tesuract.PCEReg(order=8)\n",
    "pce_score = cross_val_score(pce,X,y,scoring='r2').mean()\n",
    "print(\"PCE score is {0:.3f}\".format(pce_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03237d92",
   "metadata": {},
   "source": [
    "Not bad for a first pass. How does it compare to something like random forests regression or MLPs? Now, we can compare apples to applies within the same environment since these models are all part of the sklearn base-estimator class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c91c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF score is 0.685\n"
     ]
    }
   ],
   "source": [
    "# Let's try a simple random forest estimator\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfregr = RandomForestRegressor(max_depth=5,n_estimators=100)\n",
    "rf_score = cross_val_score(rfregr,X,y,scoring='r2').mean()\n",
    "print(\"RF score is {0:.3f}\".format(rf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "087aae85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP score is 0.939\n"
     ]
    }
   ],
   "source": [
    "# Let's try a simple 4-layer neural network (fully connected)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "mlpregr = MLPRegressor(hidden_layer_sizes=(100,100,100,100))\n",
    "mlp_score = cross_val_score(mlpregr,X,y,scoring='r2').mean()\n",
    "print(\"MLP score is {0:.3f}\".format(mlp_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875434fa",
   "metadata": {},
   "source": [
    "Wow! So the MLP way out-performed the 8th order polynomial with a linear fit! But wait. What if we tried a different polynomial order? Or a different fitting procedure like a sparse l-1 solver? Can we leverage the hyper-parameter tuning that sklearn has? Yes! Moreso, we created an easy wrapper for the grid search cv functionality and a new pce regression wrapper that has cross-validation and hyper-parameter tuning built in! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6237eb58",
   "metadata": {},
   "source": [
    "## Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede96fd5",
   "metadata": {},
   "source": [
    "There are essentially three parameters to tune in the polynomial regression class. The first, and the most obvious, is the polynomial order, which has the keyword ``order`` in the constructor. The next is the type of polynomial interaction terms called ``mindex_type``. \"total_orer\" os the default, but an alternative is \"hyperbolic\" which has even fewer interaction terms which emphasizes more higher-order terms. In practice, this rarely leads to a better polynomial, but we can try it anyway. Last, but not least, there is the polynomial ``fit_type``, which determines the solver used to solve the least squares problem (Note even though polynomials are non-linear, the fitting boils down to a linear problem). This can be a bunch of different algorithms, but the three most widely used are 'linear', 'LassoCV', and 'ElasticNetCV'. \n",
    "\n",
    "With these parameters in mind, we create a parameter grid just like one would when using the GridSearchCV method in sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "947fbc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pce_grid = {\n",
    "    'order': list(range(1,12)),\n",
    "    'mindex_type': ['total_order','hyperbolic'],\n",
    "    'fit_type': ['linear','ElasticNetCV','LassoCV'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030bc53",
   "metadata": {},
   "source": [
    "Now we use the regression wrapper CV class which wraps the PCEReg class in sklearn's grid search CV functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52590ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 66 candidates, totalling 330 fits\n",
      "Fitting 5 folds for each of 66 candidates, totalling 330 fits\n",
      "Hyper-parameter CV PCE score is 0.998\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameter tune the PCE regression class using all available cores\n",
    "pce = tesuract.RegressionWrapperCV(\n",
    "    regressor='pce',\n",
    "    reg_params=pce_grid,\n",
    "    n_jobs=-1,\n",
    "    scorer='r2')\n",
    "pce.fit(X,y)\n",
    "print(\"Hyper-parameter CV PCE score is {0:.3f}\".format(pce.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c4b367",
   "metadata": {},
   "source": [
    "Why so many fits? For each k-fold (5 total) we have to compute 66 fits corresponding to 66 different parameter combinations. This repeats five times to get an average cross validation score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b90e1",
   "metadata": {},
   "source": [
    "Look at that! We got all the way to an R2 score of basically 1! How did we do that? One of our parameter combinations must have been really good. Which one was it? We can easily find out by called the best_params_ attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "729254db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_type': 'ElasticNetCV', 'mindex_type': 'total_order', 'order': 4}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pce.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80741f5c",
   "metadata": {},
   "source": [
    "So it seems like 8th order way too high and probably overfit, so a fourth order was much better. Elastic net regularization also seemed to work the best, which uses a mix of l1 and l2 regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bac3a89",
   "metadata": {},
   "source": [
    "Now, to be fair, we probably should hyper-parameter tune the MLP regressor to perform a completely fair comparison, and it may probably give us ultimately a better model. In general however, neural networks are much hard to hyper-parameter tune and take longer to train, so the polynomial model can be preferred when accuracy and simplicity is required. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01385175",
   "metadata": {},
   "source": [
    "## Feature importances\n",
    "\n",
    "One last thing, before we move onto more advanced usage cases, in particular, tensor surrogates. With orthogonal polynomials like in PCEs, we can (almost) automatically obtain feature importances in the form of Sobol sensitivity indices. In particular, we can call feature importances to obtain normalized (summed to one) Sobol total order indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "587f855a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25341252, 0.2553728 , 0.08742023, 0.31989295, 0.08390151])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain the best estimator after hyper-parameter tuning\n",
    "pce_best = pce.best_estimator_\n",
    "# compute the normalized (sum to 1) Sobol total order indices\n",
    "pce_best.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf53116",
   "metadata": {},
   "source": [
    "Now technically, the Sobol total order indices shouldn't be normalized, but we do it for consistency and with only some loss of generality. For the original total order indices use ``computeSobol()`` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "944c0058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.27158784222563226,\n",
       " 0.27368872135122857,\n",
       " 0.09369020534664568,\n",
       " 0.34283640074485666,\n",
       " 0.0899191144641273]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pce_best.computeSobol()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d706d6",
   "metadata": {},
   "source": [
    "The larger the value, the more \"important\" the parameter is. So, the first, second and fourth parameters are more importance features in the model than the remaining two. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
